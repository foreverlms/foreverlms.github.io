---
layout: post
title: ONNX模型格式浅析(一)
date: 2021-06-12 22:58:47 +0800
categories: [笔记]
tags: [ml]
---

* content
{: toc}

神经网络模型在训练时需要进行反向传播以对参数进行优化更新，Tensorflow、Pytorch、Theano等框架都实现了基于计算图的反向传播算法。计算图表征了整个模型前向传递的过程，并可以为实现自动微分提供反向传播的路径。

{: style="text-align:center"}
![图](/images/img/onnx_model/compu_graph.png)

<center> 描述(x+y)*z的计算图 </center>

Open neural network exchange，ONNX是由微软提出的开源AI模型格式，它定义了可扩展性的计算图（算子+数据类型构成的DAG），支持在主流的各种机器学习框架间进行模型转换。ONNX文件不仅仅存储了神经网络模型的权重，同时也存储了模型的结构信息以及网络中每一层的输入输出和一些其它的辅助信息。

{: style="text-align:center"}
![图](/images/img/onnx_model/frameworks.png)

<center> 支持ONNX的框架 </center>


ONNX规范的组成部分：
- extensible computation graph：定义通用计算图的IR(Intermediate Representation)。
- 内置操作符集（operator set）：
ai.onnx //默认操作符集
ai.onnx.ml//传统非神经网络机器学习模型

- 标准数据类型（scalar type）tensor/sequence/maps

### 计算图IR表示
这里以一个由Pytorch导出的一个onnx做演示：
```python
class DemoModel(nn.Module):
    def __init__(self):
        super(DemoModel, self).__init__()
        self.features1 = nn.Sequential(
            nn.Conv2d(1, 3, 3, 1, 1),
            nn.MaxPool2d(2),
            nn.ReLU(),
        )
        self.features2 = nn.Sequential(
            nn.Conv2d(1, 3, 3, 1, 1),
            nn.MaxPool2d(2),
            nn.ReLU(),
        )
        self.features3 = nn.Sequential(
            nn.Linear(10, 5),
            nn.ReLU(),
        )

        self.classifier = nn.Linear(128*128*3 + 32*32*3 + 5, 4)
        
    def forward(self, x1, x2, x3):
        x1 = self.features1(x1)
        x2 = self.features2(x2)
        x3 = self.features3(x3)

        x1 = x1.view(x1.data.size(0), -1)
        x2 = x2.view(x2.data.size(0), -1)
        x3 = x3.view(x3.data.size(0), -1)
        
        x = torch.cat((x1, x2, x3), dim=1)
        x = self.classifier(x)
        return x

x1 = torch.randn(1,1,256,256)
x2 = torch.randn(1,1,64,64)
x3 = torch.randn(1,10)

model = DemoModel()
output = model(x1,x2,x3)

torch.onnx.export(model,
                 (x1,x2,x3),
                  "demo.onnx",
                 export_params = True,
                 input_names = ["x1","x2","x3"],
                  output_names = ["output"],
                  opset_version = 9,
                  verbose = True
                 )
```

{: style="text-align:center"}
![图](/images/img/onnx_model/model.png)

<center> Pytorch Export ONNX</center>


### Proto原型

onnx使用protobuf序列化AI模型，在onnx.proto里定义了构成模型的几种原型：

- ModelProto
- AttributeProto
- TensorProto
- GraphProto
- NodeProto
- ValueInfoProto

下面笔者详细介绍下几个比较基础的Proto的定义：

- TensorProto

TensorProto是数据的实际持有类型，ONNX里的权重，tensor等等，最后都会由TensorProto表示。TensorProto支持固定的数据类型，在指定数据类型后，其对应的存放数据的type_data也随之确定。实际上，相当部分Tensor直接使用了raw_data来存储数据。

- ValueInfroProto

```protobuf
message ValueInfoProto {
  // This field MUST be present in this version of the IR.
  optional string name = 1;     // namespace Value
  // This field MUST be present in this version of the IR for
  // inputs and outputs of the top-level graph.
  optional TypeProto type = 2;
  // A human-readable documentation for this value. Markdown is allowed.
  optional string doc_string = 3;
}
```

ValueInfoProto中的两个主要属性：name，type。name记录了其代表的具体数据/节点的名称，type是TypeProto原型，其可以指明数据类型为Tensor、Sequence、Map、SparseTensor中的其中一种。可以看出，ValueInfoProto并不实际持有数据，只是对数据的描述。

- AttributeProto

AttributeProto描述数据/算子的属性。首先其内部定义了一个AttributeType enum，表明其所描述的数据主体是哪一种（个人理解）：

```protobuf
enum AttributeType {
  UNDEFINED = 0;
  FLOAT = 1;
  INT = 2;
  STRING = 3;
  TENSOR = 4;
  GRAPH = 5;
  SPARSE_TENSOR = 11;

  FLOATS = 6;
  INTS = 7;
  STRINGS = 8;
  TENSORS = 9;
  GRAPHS = 10;
  SPARSE_TENSORS = 12;
}
```

例如`AttributeType::INTS`表示当前的Attribute里是一串数字，以卷积的一个kernel_shape属性为例：

```protobuf
attribute {
  name: "kernel_shape"
  ints: 3
  ints: 3
  type: INTS
}
```

这是一个3x3大小的卷积核。

AttributeProto具有的其他字段很多，大部分都定义成了optional，因此可以对各个算子的固有属性进行描述。每种类型应该定义什么样的Attribute，在onnx的[Operator文档]里可以查询。

- NodeProto

NodeProto的定义依赖于AttributeTypeProto：
```protobuf
message NodeProto {
  repeated string input = 1;    // namespace Value
  repeated string output = 2;   // namespace Value

  // An optional identifier for this node in a graph.
  // This field MAY be absent in ths version of the IR.
  optional string name = 3;     // namespace Node

  // The symbolic identifier of the Operator to execute.
  optional string op_type = 4;  // namespace Operator
  // The domain of the OperatorSet that specifies the operator named by op_type.
  optional string domain = 7;   // namespace Domain

  // Additional named attributes.
  repeated AttributeProto attribute = 5;

  // A human-readable documentation for this node. Markdown is allowed.
  optional string doc_string = 6;
}
```

可以看到，input和output分别指定当前算子节点的输入输出namespace，op_type指定算子类型，attribute指明算子的属性。

### ONNX Model结构

ONNX的模型加载进来是ModelProto类型，一个ModelProto原型是对整个模型的描述，它包含onnx版本信息、算子版本等等，其中最重要的是GraphProto，是对计算图的描述。
我们用Netron打开上面保存的模型，可以看到显示的model信息：


{: style="text-align:center"}
![图](/images/img/onnx_model/model_property.png)

<center>Netron里显示ModelProto的基础信息 </center>


GraphProto的定义中包含四个repeated message，分别是：
- node→NodeProto 模型的计算节点，也可以理解成一个独立的层 [repeated]
- input→ValueInfoProto 模型的输入信息 [repeated]
- output→ValueInfoProto 模型的输出信息 [repeated]
- initializer→TensorProto 模型的参数信息 [repeated]

node中同样包含有input和output属性，其为repeated string，分别指向其他节点的输出和指定当前节点的输出。node的op_type属性指明当前节点的算子类型。每个节点node具有repeated AttributeProro属性，描述了节点算子的一些属性，如卷积层的kernel，pooling等等。

`input`和`output`指定模型的输入输出，即上图的INPUTS和OUTPUTS。

`initializer`是`TenrsorProto`数组，包含整个模型预训练好的权重、常量之类的数据。

### 构造ONNX模型

在使用Pytorch/Tensotflow等框架训练好模型后，我们可以很方便地导出不同格式的模型，包括onnx、pb等。这些内建工具方便了我们，但是了解onnx的模型是如何构造的还是很有必要的。

#### Helper Function

上面提到了ONNX模型由一系列Proto组成，通过ONNX提供的一些helper function我们可以构造出来模型。onnx提供的一些helper function如下：
```python
def make_tensor(
        name,  # type: Text
        data_type,  # type: int
        dims,  # type: Sequence[int]
        vals,  # type: Any
        raw=False  # type: bool
):  # type: (...) -> TensorProto

def make_attribute(
        key,  # type: Text
        value,  # type: Any
        doc_string=None  # type: Optional[Text]
):  # type: (...) -> AttributeProto

def make_tensor_value_info(
        name,  # type: Text
        elem_type,  # type: int
        shape,  # type: Optional[Sequence[Union[Text, int]]]
        doc_string="",  # type: Text
        shape_denotation=None,  # type: Optional[List[Text]]
):  # type: (...) -> ValueInfoProto

def make_node(
        op_type,  # type: Text
        inputs,  # type: Sequence[Text]
        outputs,  # type: Sequence[Text]
        name=None,  # type: Optional[Text]
        doc_string=None,  # type: Optional[Text]
        domain=None,  # type: Optional[Text]
        **kwargs  # type: Any
):  # type: (...) -> NodeProto


def make_graph(
    nodes,  # type: Sequence[NodeProto]
    name,  # type: Text
    inputs,  # type: Sequence[ValueInfoProto]
    outputs,  # type: Sequence[ValueInfoProto]
    initializer=None,  # type: Optional[Sequence[TensorProto]]
    doc_string=None,  # type: Optional[Text]
    value_info=[],  # type: Sequence[ValueInfoProto]
    sparse_initializer=None,  # type: Optional[Sequence[SparseTensorProto]]
):  # type: (...) -> GraphProto

def make_model(graph, **kwargs):  # type: (GraphProto, **Any) -> ModelProto

```

### Demo

#### From Scratch to Model

这部分可以参照ONNX的官方文档。

#### Simplify Model

This will be released soon.

### Reference

1. [onnx/onnx](https://github.com/onnx/onnx)
2. [开源一年多的模型交换格式ONNX，已经一统框架江湖了？](https://zhuanlan.zhihu.com/p/51387600)
3. [ONNX学习笔记](https://zhuanlan.zhihu.com/p/346511883)